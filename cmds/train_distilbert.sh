#!/bin/bash

# DistilBERT Model Training Script
# This script trains the DistilBERT model using a pre-existing tokenizer

set -e  # Exit on any error

echo "ü§ñ Starting DistilBERT model training..."
echo

# Check if processed data exists
if [ ! -f "benign_processed.csv" ] || [ ! -f "malicious_processed.csv" ]; then
    echo "‚ùå Error: Processed data files not found"
    echo "   Please run preprocess_data.sh first to generate processed data"
    exit 1
fi

echo "‚úÖ Processed data files found"

# Check if tokenizer exists
if [ ! -f "malwi_models/tokenizer.json" ]; then
    echo "‚ùå Error: No tokenizer found at malwi_models/"
    echo "   Please run train_tokenizer.sh first to create the tokenizer"
    exit 1
fi

echo "‚úÖ Tokenizer found at malwi_models/"
echo

# Train DistilBERT model
echo "üöÄ Training DistilBERT model..."
echo "   ‚Ä¢ Loading pre-trained tokenizer from malwi_models/"
echo "   ‚Ä¢ Training data: benign_processed.csv, malicious_processed.csv"
echo "   ‚Ä¢ Model size: 256 hidden dimensions (smaller, faster model)"
echo "   ‚Ä¢ Epochs: 3"
echo "   ‚Ä¢ Using 1 processor for training"
echo
echo "   Note: Use --hidden-size 512 for larger model with better accuracy"
echo

uv run python -m src.research.train_distilbert \
    -b benign_processed.csv \
    -m malicious_processed.csv \
    --epochs 3 \
    --hidden-size 256 \
    --num-proc 1

echo
echo "üéâ DistilBERT model training completed!"
echo
echo "üìã Model files saved to malwi_models/:"
echo "   ‚Ä¢ Trained DistilBERT model weights and config"
echo "   ‚Ä¢ Training metrics and logs"
echo "   ‚Ä¢ Pre-existing tokenizer (preserved)"
echo