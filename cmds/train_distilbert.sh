#!/bin/bash

# DistilBERT Training Script: Tokenizer + Model Training
# This script trains both the tokenizer and DistilBERT model

set -e  # Exit on any error

echo "ü§ñ Starting DistilBERT training pipeline..."
echo "   This includes: Tokenizer training ‚Üí Model training"
echo

# Check if processed data exists
if [ ! -f "benign_processed.csv" ] || [ ! -f "malicious_processed.csv" ]; then
    echo "‚ùå Error: Processed data files not found"
    echo "   Please run data preprocessing first to generate processed data"
    exit 1
fi

echo "‚úÖ Processed data files found"
echo

# Step 1: Train tokenizer
echo "üî§ Step 1: Training custom tokenizer..."
echo "   ‚Ä¢ Using top 5000 most frequent tokens from data"
echo "   ‚Ä¢ Training on: benign_processed.csv, malicious_processed.csv"
echo "   ‚Ä¢ Output: malwi_models/"
echo

uv run python -m src.research.train_tokenizer \
    -b benign_processed.csv \
    -m malicious_processed.csv \
    -o malwi_models \
    --top-n-tokens 5000 \
    --save-computed-tokens \
    --force-retrain

echo "‚úÖ Tokenizer training completed"
echo

# Step 2: Train DistilBERT model
echo "üöÄ Step 2: Training DistilBERT model..."
echo "   ‚Ä¢ Loading custom tokenizer from malwi_models/"
echo "   ‚Ä¢ Training data: benign_processed.csv, malicious_processed.csv"
echo "   ‚Ä¢ Epochs: 3"
echo "   ‚Ä¢ Using 1 processor for training"
echo

uv run python -m src.research.train_distilbert \
    -b benign_processed.csv \
    -m malicious_processed.csv \
    --epochs 3 \
    --num-proc 1

echo
echo "üéâ DistilBERT training pipeline completed!"
echo
echo "üìã Generated files in malwi_models/:"
echo "   ‚Ä¢ Custom tokenizer (trained on your data's top 5000 tokens)"
echo "   ‚Ä¢ Computed special tokens list"
echo "   ‚Ä¢ Trained DistilBERT model weights and config"
echo "   ‚Ä¢ Training metrics and logs"
echo